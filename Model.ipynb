{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "561b3d04",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sentence_transformers.losses import CosineSimilarityLoss\n",
    "\n",
    "from datasets import Dataset, load_dataset\n",
    "from setfit import SetFitModel, SetFitTrainer\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1ed4ae3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/siddharthmandgi/Desktop/Data-Science-Universe/Projects/Twitter-Sentiment-Analysis'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0010f970",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd9cb512",
   "metadata": {},
   "source": [
    "### 1. Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a64f3ca7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>im getting on borderlands and i will murder yo...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I am coming to the borders and I will kill you...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>im getting on borderlands and i will kill you ...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>im coming on borderlands and i will murder you...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>im getting on borderlands 2 and i will murder ...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73991</th>\n",
       "      <td>Just realized that the Windows partition of my...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73992</th>\n",
       "      <td>Just realized that my Mac window partition is ...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73993</th>\n",
       "      <td>Just realized the windows partition of my Mac ...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73994</th>\n",
       "      <td>Just realized between the windows partition of...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73995</th>\n",
       "      <td>Just like the windows partition of my Mac is l...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>73996 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   tweet sentiment\n",
       "0      im getting on borderlands and i will murder yo...  Positive\n",
       "1      I am coming to the borders and I will kill you...  Positive\n",
       "2      im getting on borderlands and i will kill you ...  Positive\n",
       "3      im coming on borderlands and i will murder you...  Positive\n",
       "4      im getting on borderlands 2 and i will murder ...  Positive\n",
       "...                                                  ...       ...\n",
       "73991  Just realized that the Windows partition of my...  Positive\n",
       "73992  Just realized that my Mac window partition is ...  Positive\n",
       "73993  Just realized the windows partition of my Mac ...  Positive\n",
       "73994  Just realized between the windows partition of...  Positive\n",
       "73995  Just like the windows partition of my Mac is l...  Positive\n",
       "\n",
       "[73996 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv(\"./twitter_training.csv\", header=None)\n",
    "train.rename(columns={0:'tweet_id', 1:'entity', 2:'sentiment', 3:'tweet'},inplace=True)\n",
    "train = train.dropna().reset_index(drop=True)\n",
    "train_id = train['tweet_id']\n",
    "train['sentiment_label'] = train['sentiment'].astype('category').cat.codes\n",
    "train = train[['tweet', 'sentiment']]\n",
    "train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05df8306",
   "metadata": {},
   "source": [
    "### 2. Validation Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "98d50008",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>sentiment_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I mentioned on Facebook that I was struggling ...</td>\n",
       "      <td>Irrelevant</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BBC News - Amazon boss Jeff Bezos rejects clai...</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@Microsoft Why do I pay for WORD when it funct...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CSGO matchmaking is so full of closet hacking,...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Now the President is slapping Americans in the...</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>⭐️ Toronto is the arts and culture capital of ...</td>\n",
       "      <td>Irrelevant</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>tHIS IS ACTUALLY A GOOD MOVE TOT BRING MORE VI...</td>\n",
       "      <td>Irrelevant</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>Today sucked so it’s time to drink wine n play...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>Bought a fraction of Microsoft today. Small wins.</td>\n",
       "      <td>Positive</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>Johnson &amp; Johnson to stop selling talc baby po...</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 tweet   sentiment  \\\n",
       "0    I mentioned on Facebook that I was struggling ...  Irrelevant   \n",
       "1    BBC News - Amazon boss Jeff Bezos rejects clai...     Neutral   \n",
       "2    @Microsoft Why do I pay for WORD when it funct...    Negative   \n",
       "3    CSGO matchmaking is so full of closet hacking,...    Negative   \n",
       "4    Now the President is slapping Americans in the...     Neutral   \n",
       "..                                                 ...         ...   \n",
       "995  ⭐️ Toronto is the arts and culture capital of ...  Irrelevant   \n",
       "996  tHIS IS ACTUALLY A GOOD MOVE TOT BRING MORE VI...  Irrelevant   \n",
       "997  Today sucked so it’s time to drink wine n play...    Positive   \n",
       "998  Bought a fraction of Microsoft today. Small wins.    Positive   \n",
       "999  Johnson & Johnson to stop selling talc baby po...     Neutral   \n",
       "\n",
       "     sentiment_label  \n",
       "0                  0  \n",
       "1                  2  \n",
       "2                  1  \n",
       "3                  1  \n",
       "4                  2  \n",
       "..               ...  \n",
       "995                0  \n",
       "996                0  \n",
       "997                3  \n",
       "998                3  \n",
       "999                2  \n",
       "\n",
       "[1000 rows x 3 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val = pd.read_csv(\"./twitter_validation.csv\", header=None)\n",
    "val.rename(columns={0:'tweet_id', 1:'entity', 2:'sentiment', 3:'tweet'},inplace=True)\n",
    "val_id = val['tweet_id']\n",
    "val = val[['tweet', 'sentiment']]\n",
    "val['sentiment_label'] = val['sentiment'].astype('category').cat.codes\n",
    "val"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2394013",
   "metadata": {},
   "source": [
    "# Sentence Transformer Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "142e368b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = SentenceTransformer('paraphrase-mpnet-base-v2')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14e3334b",
   "metadata": {},
   "source": [
    "### 1. Train embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5185f299",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_embeddings = model.encode(train['tweet'])\n",
    "train_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "375d5fda",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_embeddings_dataframe = pd.DataFrame(train_embeddings)\n",
    "train_embeddings_dataframe['tweet_id'] = train_id\n",
    "train_embeddings_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29219a2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_embeddings_dataframe.to_csv(\"train_embeddings.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cad92bc2",
   "metadata": {},
   "source": [
    "### 2. Validation embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69c8b4fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_embeddings = model.encode(val['tweet'])\n",
    "val_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b384b63",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_embeddings_dataframe = pd.DataFrame(val_embeddings)\n",
    "val_embeddings_dataframe['tweet_id'] = val_id\n",
    "val_embeddings_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fe792ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_embeddings_dataframe.to_csv(\"val_embeddings.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d041c54",
   "metadata": {},
   "source": [
    "### 3. Classification Head \n",
    "- Run from Here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cce9c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_embeddings_dataframe = pd.read_csv(\"train_embeddings.csv\")\n",
    "val_embeddings_dataframe = pd.read_csv(\"val_embeddings.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af4273a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_embeddings_dataframe.drop(['tweet_id'],axis=1)\n",
    "y_train = train['sentiment_label']\n",
    "\n",
    "X_val = val_embeddings_dataframe.drop(['tweet_id'],axis=1)\n",
    "y_val = val['sentiment_label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c90d7a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = RandomForestClassifier()\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01c5cc44",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_val, classifier.predict(X_val)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9359dd2",
   "metadata": {},
   "source": [
    "# Finetuning with SetFit on unique tweet ids (few samples)\n",
    "- 100 Samples of each sentiment of unique tweet ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e971a0ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "train_unique = train\n",
    "train_unique['tweet_id'] = train_id\n",
    "\n",
    "\n",
    "\n",
    "train_unique = train_unique.sample(frac=1.0)\n",
    "\n",
    "# get first of every tweet in tweet_id\n",
    "train_unique = train_unique.groupby(\"tweet_id\").head(1000)\n",
    "\n",
    "# Take only 100 samples of each class (sentiment)\n",
    "train_unique = train_unique.groupby(\"sentiment\").head(1000)\n",
    "\n",
    "train_unique"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e5f59b9",
   "metadata": {},
   "source": [
    "### 1. Preparing Torch Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63852284",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_dict = {'sentence':train_unique['tweet'], 'label': train_unique['sentiment_label']}\n",
    "\n",
    "train_dataset = Dataset.from_dict(my_dict)\n",
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9dfa2b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_dict = {'sentence':val['tweet'], 'label': val['sentiment_label']}\n",
    "\n",
    "val_dataset = Dataset.from_dict(my_dict)\n",
    "val_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d23c7fc1",
   "metadata": {},
   "source": [
    "### 2. Load Finetune Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45b50381",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a SetFit model from Hub\n",
    "model = SetFitModel.from_pretrained(\"sentence-transformers/paraphrase-mpnet-base-v2\")\n",
    "\n",
    "# Create trainer\n",
    "trainer = SetFitTrainer(\n",
    "    model=model,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    loss_class=CosineSimilarityLoss,\n",
    "    metric=\"accuracy\",\n",
    "    batch_size=16,\n",
    "    num_iterations=20, # The number of text pairs to generate for contrastive learning\n",
    "    num_epochs=1, # The number of epochs to use for contrastive learning\n",
    "    column_mapping={\"sentence\": \"text\", \"label\": \"label\"} # Map dataset columns to text/label expected by trainer\n",
    ")\n",
    "\n",
    "# Train and evaluate\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c70a8845",
   "metadata": {},
   "source": [
    "### 3. Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a2180b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"./saved_models\"\n",
    "isExist = os.path.exists(path)\n",
    "if not isExist:\n",
    "\n",
    "   # Create a new directory because it does not exist\n",
    "   os.makedirs(path)\n",
    "    \n",
    "    \n",
    "trainer.model._save_pretrained(\"/saved_models/finetuned_paraphrase-mpnet-base-v2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be1730cb",
   "metadata": {},
   "source": [
    "### 4. Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79785e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_model = SetFitModel._from_pretrained(\"finetuned_paraphrase-mpnet-base-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47a70cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_embeddings = saved_model.model_body.encode(train['tweet'])\n",
    "train_embeddings_dataframe = pd.DataFrame(train_embeddings)\n",
    "train_embeddings_dataframe['tweet_id'] = train_id\n",
    "\n",
    "val_embeddings = saved_model.model_body.encode(val['tweet'])\n",
    "val_embeddings_dataframe = pd.DataFrame(val_embeddings)\n",
    "val_embeddings_dataframe['tweet_id'] = val_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1f527f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_embeddings_dataframe.to_csv(\"finetuned_train_embeddings.csv\", index=False)\n",
    "val_embeddings_dataframe.to_csv(\"finetuned_val_embeddings.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "146f10e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_embeddings_dataframe.drop(['tweet_id'],axis=1)\n",
    "y_train = train['sentiment_label']\n",
    "X_val = val_embeddings_dataframe.drop(['tweet_id'],axis=1)\n",
    "y_val = val['sentiment_label']\n",
    "            \n",
    "classifier = RandomForestClassifier()\n",
    "classifier.fit(X_train, y_train)\n",
    "            \n",
    "print(classification_report(y_val, classifier.predict(X_val)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
